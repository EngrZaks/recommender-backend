{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this article is the open sourced dataset, which contains 100836 data points, by movielens.\n",
    "https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mratings.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('timestamp',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.iloc[:int(data.shape[0]*0.80)]\n",
    "test_data=data.iloc[int(data.shape[0]*0.80):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD MF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD\n",
    "\n",
    "__ Predicted Rating : __\n",
    "\n",
    "𝑟̂ 𝑢𝑖=𝜇+𝑏𝑢+𝑏𝑖+𝑞𝑇𝑖𝑝𝑢\n",
    "𝑞𝑞𝑖 - Representation of item(movie) in latent factor space\n",
    "\n",
    "𝑝𝑝𝑢 - Representation of user in new latent factor space\n",
    "\n",
    "A BASIC MATRIX FACTORIZATION MODEL in https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf\n",
    "Optimization problem with user item interactions and regularization (to avoid overfitting)\n",
    "∑𝑟𝑢𝑖∈𝑅𝑡𝑟𝑎𝑖𝑛(𝑟𝑢𝑖−𝑟̂ 𝑢𝑖)2+𝜆(𝑏2𝑖+𝑏2𝑢+||𝑞𝑖||2+||𝑝𝑢||2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "import numpy as np\n",
    "import surprise\n",
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is to specify how to read the dataframe.\n",
    "# for our dataframe, we don't have to specify anything extra..\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the dataframe...\n",
    "train_data_mf = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# build the trainset from traindata.., It is of dataset format from surprise library..\n",
    "trainset = train_data_mf.build_full_trainset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is to specify how to read the dataframe.\n",
    "# for our dataframe, we don't have to specify anything extra..\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the dataframe...\n",
    "test_data_mf = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# build the trainset from traindata.., It is of dataset format from surprise library..\n",
    "testset = test_data_mf.build_full_trainset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions of trainset\n",
    "train_preds = svd.test(trainset.build_testset())\n",
    "\n",
    "train_pred_mf = np.array([pred.est for pred in train_preds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions of trainset\n",
    "test_preds = svd.test(testset.build_testset())\n",
    "\n",
    "test_pred_mf = np.array([pred.est for pred in test_preds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_mf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing train data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sparse matrix\n",
    "train_sparse_matrix = sparse.csr_matrix((train_data.rating.values, (train_data.userId.values,\n",
    "                                               train_data.movieId.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global avg of all movies by all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages = dict()\n",
    "# get the global average of ratings in our train set.\n",
    "train_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "train_averages['global'] = train_global_average\n",
    "train_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user averages in dictionary (key: user_id/movie_id, value: avg rating)\n",
    "\n",
    "def get_average_ratings(sparse_matrix, of_users):\n",
    "    \n",
    "    # average ratings of user/axes\n",
    "    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n",
    "\n",
    "    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    # Boolean matrix of ratings ( whether a user rated that movie or not)\n",
    "    is_rated = sparse_matrix!=0\n",
    "    # no of ratings that each user OR movie..\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    # max_user  and max_movie ids in sparse matrix \n",
    "    u,m = sparse_matrix.shape\n",
    "    # creae a dictonary of users and their average ratigns..\n",
    "    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                 for i in range(u if of_users else m) \n",
    "                                    if no_of_ratings[i] !=0}\n",
    "\n",
    "    # return that dictionary of average ratings\n",
    "    return average_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ratings given by a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\n",
    "print('\\nAverage rating of user 10 :',train_averages['user'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ratings given for a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\n",
    "print('\\n AVerage rating of movie 15 :',train_averages['movie'][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users, movies and ratings from our samples train sparse matrix\n",
    "train_users, train_movies, train_ratings = sparse.find(train_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame()\n",
    "count = 0\n",
    "for (user, movie, rating)  in zip(train_users, train_movies, train_ratings):\n",
    "            st = datetime.now()\n",
    "        #     print(user, movie)    \n",
    "            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n",
    "            # compute the similar Users of the \"user\"        \n",
    "            user_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\n",
    "            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "            # get the ratings of most similar users for this movie\n",
    "            top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding movie averages to .\n",
    "            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "        #     print(top_sim_users_ratings, end=\" \")    \n",
    "\n",
    "\n",
    "            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n",
    "            # compute the similar movies of the \"movie\"        \n",
    "            movie_sim = cosine_similarity(train_sparse_matrix[:,movie].T, train_sparse_matrix.T).ravel()\n",
    "            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "            # get the ratings of most similar movie rated by this user..\n",
    "            top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding user averages to.\n",
    "            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n",
    "        #     print(top_sim_movies_ratings, end=\" : -- \")\n",
    "\n",
    "            #-----------------prepare the row to be stores in a file-----------------#\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            # Now add the other features to this data...\n",
    "            row.append(train_averages['global']) # first feature\n",
    "            # next 5 features are similar_users \"movie\" ratings\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            # next 5 features are \"user\" ratings for similar_movies\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            # Avg_user rating\n",
    "            row.append(train_averages['user'][user])\n",
    "            # Avg_movie rating\n",
    "            row.append(train_averages['movie'][movie])\n",
    "\n",
    "            # finalley, The actual Rating of this user-movie pair...\n",
    "            row.append(rating)\n",
    "            count = count + 1\n",
    "            final_data = final_data.append([row])\n",
    "            print(count)\n",
    "\n",
    "           \n",
    "        \n",
    "            if (count)%10000 == 0:\n",
    "                # print(','.join(map(str, row)))\n",
    "                print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.columns=['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "            'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_data\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_data' is not defined"
     ]
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['mf_svd']=train_pred_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sparse matrix\n",
    "test_sparse_matrix = sparse.csr_matrix((test_data.rating.values, (test_data.userId.values,\n",
    "                                               test_data.movieId.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global avg of all movies by all users\n",
    "\n",
    "test_averages = dict()\n",
    "# get the global average of ratings in our train set.\n",
    "test_global_average = test_sparse_matrix.sum()/test_sparse_matrix.count_nonzero()\n",
    "test_averages['global'] = test_global_average\n",
    "test_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the user averages in dictionary (key: user_id/movie_id, value: avg rating)\n",
    "\n",
    "def get_average_ratings(sparse_matrix, of_users):\n",
    "    \n",
    "    # average ratings of user/axes\n",
    "    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n",
    "\n",
    "    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    # Boolean matrix of ratings ( whether a user rated that movie or not)\n",
    "    is_rated = sparse_matrix!=0\n",
    "    # no of ratings that each user OR movie..\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    # max_user  and max_movie ids in sparse matrix \n",
    "    u,m = sparse_matrix.shape\n",
    "    # creae a dictonary of users and their average ratigns..\n",
    "    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                 for i in range(u if of_users else m) \n",
    "                                    if no_of_ratings[i] !=0}\n",
    "\n",
    "    # return that dictionary of average ratings\n",
    "    return average_ratings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ratings given by a user\n",
    "\n",
    "test_averages['user'] = get_average_ratings(test_sparse_matrix, of_users=True)\n",
    "#print('\\nAverage rating of user 10 :',test_averages['user'][10])\n",
    "\n",
    "# Average ratings given for a movie\n",
    "\n",
    "test_averages['movie'] =  get_average_ratings(test_sparse_matrix, of_users=False)\n",
    "print('\\n AVerage rating of movie 15 :',test_averages['movie'][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users, movies and ratings from our samples train sparse matrix\n",
    "test_users, test_movies, test_ratings = sparse.find(test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data = pd.DataFrame()\n",
    "count = 0\n",
    "for (user, movie, rating)  in zip(test_users, test_movies, test_ratings):\n",
    "            st = datetime.now()\n",
    "        #     print(user, movie)    \n",
    "            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n",
    "            # compute the similar Users of the \"user\"        \n",
    "            user_sim = cosine_similarity(test_sparse_matrix[user], test_sparse_matrix).ravel()\n",
    "            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "            # get the ratings of most similar users for this movie\n",
    "            top_ratings = test_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding movie averages to .\n",
    "            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_users_ratings.extend([test_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "        #     print(top_sim_users_ratings, end=\" \")    \n",
    "\n",
    "\n",
    "            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n",
    "            # compute the similar movies of the \"movie\"        \n",
    "            movie_sim = cosine_similarity(test_sparse_matrix[:,movie].T, test_sparse_matrix.T).ravel()\n",
    "            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n",
    "            # get the ratings of most similar movie rated by this user..\n",
    "            top_ratings = test_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding user averages to.\n",
    "            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_movies_ratings.extend([test_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n",
    "        #     print(top_sim_movies_ratings, end=\" : -- \")\n",
    "\n",
    "            #-----------------prepare the row to be stores in a file-----------------#\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            # Now add the other features to this data...\n",
    "            row.append(test_averages['global']) # first feature\n",
    "            # next 5 features are similar_users \"movie\" ratings\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            # next 5 features are \"user\" ratings for similar_movies\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            # Avg_user rating\n",
    "            row.append(test_averages['user'][user])\n",
    "            # Avg_movie rating\n",
    "            row.append(test_averages['movie'][movie])\n",
    "\n",
    "            # finalley, The actual Rating of this user-movie pair...\n",
    "            row.append(rating)\n",
    "            count = count + 1\n",
    "            final_test_data = final_test_data.append([row])\n",
    "            print(count)\n",
    "\n",
    "           \n",
    "        \n",
    "            if (count)%10000 == 0:\n",
    "                # print(','.join(map(str, row)))\n",
    "                print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data.columns=['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "            'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_mf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data['mf_svd']=test_pred_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train data\n",
    "x_train = final_data.drop(['user', 'movie','rating'], axis=1)\n",
    "y_train = final_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Test data\n",
    "x_test = final_test_data.drop(['user','movie','rating'], axis=1)\n",
    "y_test = final_test_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize XGBoost model...\n",
    "xgb_model = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\n",
    "# dictionaries for storing train and test results\n",
    "train_results = dict()\n",
    "test_results = dict()\n",
    "    \n",
    "    \n",
    "# fit the model\n",
    "print('Training the model..')\n",
    "start =datetime.now()\n",
    "xgb_model.fit(x_train, y_train, eval_metric = 'rmse')\n",
    "print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n",
    "print('Done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from the trained model, get the predictions....\n",
    "print('Evaluating the model with TRAIN data...')\n",
    "start =datetime.now()\n",
    "y_train_pred = xgb_model.predict(x_train)\n",
    "# get the rmse and mape of train data...\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "    \n",
    "# store the results in train_results dictionary..\n",
    "train_results = {'rmse': rmse_train,\n",
    "                    'mape' : mape_train,\n",
    "                    'predictions' : y_train_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#######################################\n",
    "# get the test data predictions and compute rmse and mape\n",
    "print('Evaluating Test data')\n",
    "y_test_pred = xgb_model.predict(x_test) \n",
    "rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n",
    "# store them in our test results dictionary.\n",
    "test_results = {'rmse': rmse_test,\n",
    "                    'mape' : mape_test,\n",
    "                    'predictions':y_test_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
